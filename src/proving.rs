//! Generate DV Snark Proof
//!
use crate::artifacts::{
    BAR_WTS, R1CS_CONSTRAINTS_FILE, SRS_G_K_0, SRS_G_K_1, SRS_G_K_2, SRS_G_M, SRS_G_Q, TREE_2N,
    Z_POLY, Z_VALS2_INV,
};
use crate::curve::{CompressedCurvePoint, CurvePoint, Fr, FrBits, multi_scalar_mul};
use crate::ec_fft::{
    build_sect_ecfft_tree, evaluate_poly_at_alpha_using_barycentric_weights, get_both_domains,
};
use crate::io_utils::{read_fr_vec_from_file, read_point_vec_from_file};
use crate::srs::SRS;
use crate::tree_io::{read_fftree_from_file, read_minimal_fftree_from_file, write_fftree_to_file};
use anyhow::{Context, Result};
use ark_ff::{AdditiveGroup, One, PrimeField, Zero};
use ark_poly::univariate::DensePolynomial;
use ark_std::vec::Vec;
use blake3::Hash;
use ecfft::FFTree;
use num_bigint::BigUint;
use rayon::iter::{IntoParallelIterator, ParallelIterator};
use std::path::Path;

use crate::gnark_r1cs::{R1CSInstance, evaluate_monomial_basis_poly};

/// Contains Proof generated by the prover
///
/// # Fields
///
/// * `commit_p`: Commitment to Witness and Quotient Polynomials
/// * `kzg_k`: Commitment to polynomial openings at Fiat-Shamir challenge
/// * `a0`: Witness polynomial a(X) evaluated at challenge
/// * `b0`: Witness polynomial b(X) evaluated at challenge
/// * `i0`: Public Input polynomial i(X) evaluated at challenge
///
/// We require the proof to be of small size, so we represent the data in compressed form
/// Total Size = 2 * (Compressed Curve Point) 30 bytes + 3 * (Scalr Field ELement) 29 bytes = 147 bytes
#[derive(Clone, Debug, PartialEq, Eq)]
pub struct Proof {
    /// commit_p
    pub commit_p: CompressedCurvePoint,
    /// kzg_k
    pub kzg_k: CompressedCurvePoint,
    /// a0
    pub a0: FrBits,
    /// b0
    pub b0: FrBits,
}

/// Contains transcript necessary to obtain Fiat-Shamir challenge.
///
/// Transcript includes structures known at compile-time (circuit info & SRS) and at run-time
/// (witness commitment and public inputs)
/// `Challenge` is constructed by first merkelizing different fields of transcript, and then by truncating
/// the first 3 bytes to obtain a 224-bit number, that easily fits in a 232 bit scalar field.
/// `Challenge` should not be an element in domain D U D'. Assertion fails and prover panics if so.
/// The size of D U D' is 2^24 and the size of sample space is 2^224, so 2^{-200} probability of this happening.
///
/// # Fields
///
/// * `srs_hash`: hash of `SRS`
/// * `circuit_info_hash`: hash of `R1CSInstance`
/// * `witness_commitment_hash`: hash of commitment to witness polynomial `Proof::commit_p`
/// * `public_input_hash`: hash of public inputs
///
/// Implementation includes methods to fill in the fields above with suitable inputs and
/// a function `Transcript::output()` to obtain the `challenge` point. We expect compile time hashes `srs_hash` and
/// `circuit_info_hash`  to directly be hard-coded in code.
#[derive(Debug, Default)]
pub struct Transcript {
    srs_hash: Option<Hash>,
    circuit_info_hash: Option<Hash>,
    witness_commitment_hash: Option<Hash>,
    public_input_hash: Option<Hash>,
}

impl Transcript {
    /// Hash SRS
    // SRS is function of domain, trapdoor and circuit
    pub(crate) fn srs_hash(&mut self, srs: &SRS) {
        self.srs_hash = {
            let num_constraints = srs.g_k[0].len();
            let size = (5 * num_constraints) * 30; // G_* num_constraints * 30_bytes
            let buffer: Vec<u8> = Vec::with_capacity(size);
            // commented out for now because it takes awfully long to hash
            // this much data; these are constants known at compile time
            // so can be computed once and baked in
            /*
               for g_ks in &srs.g_k {
                   for g_k in g_ks {
                       buffer.extend_from_slice(&g_k.to_bytes());
                   }
               }
               for g_q in &srs.g_q {
                   buffer.extend_from_slice(&g_q.to_bytes());
               }
               for g_m in &srs.g_m {
                   buffer.extend_from_slice(&g_m.to_bytes());
               }
            */

            let srs_hash = blake3::hash(&buffer);
            Some(srs_hash)
        };
    }

    /// Hash circuit representation given by `R1CSInstance`
    // maybe directly use SP1 verification key hash here ??
    pub(crate) fn circuit_info_hash(&mut self, r1cs: &R1CSInstance) {
        self.circuit_info_hash = {
            let num_len: usize = r1cs.coeffs.len();
            let mut coeff_buffer = Vec::with_capacity(num_len * 32);
            let mut r1cs_buffer = Vec::new();

            // commented out for the same reason as above; takes too long to compute and is hardcoded in practice
            /*
                r1cs.coeffs.serialize_uncompressed(&mut coeff_buffer).unwrap();
                r1cs.rows.iter().for_each(|x| {
                    let mut l_bytes: Vec<u8> = x.l.par_iter().map(|t| t.coeff_id.to_le_bytes()).flatten().collect();
                    let mut r_bytes: Vec<u8> = x.r.par_iter().map(|t| t.coeff_id.to_le_bytes()).flatten().collect();
                    let mut o_bytes: Vec<u8> = x.o.par_iter().map(|t| t.coeff_id.to_le_bytes()).flatten().collect();
                    r1cs_buffer.append(&mut l_bytes);
                    r1cs_buffer.append(&mut r_bytes);
                    r1cs_buffer.append(&mut o_bytes);
                });
            */

            r1cs_buffer.append(&mut coeff_buffer);
            let r1cs_hash = blake3::hash(&r1cs_buffer);
            Some(r1cs_hash)
        };
    }

    /// Hash commitment to witness polynomial
    pub(crate) fn witness_commitment_hash(&mut self, witness_commitment: &[CurvePoint]) {
        self.witness_commitment_hash = {
            let buf: Vec<u8> = witness_commitment
                .iter()
                .flat_map(|cp| cp.to_bytes())
                .collect();
            let buf_hash = blake3::hash(&buf);
            Some(buf_hash)
        };
    }

    /// Hash public inputs
    pub(crate) fn public_input_hash(&mut self, public_inputs: &Vec<Fr>) {
        self.public_input_hash = {
            let mut buf = Vec::new();
            for pubin in public_inputs {
                let pubin_uint: BigUint = pubin.into_bigint().into();
                let mut bytes = pubin_uint.to_bytes_le();
                buf.append(&mut bytes);
            }
            let buf_hash = blake3::hash(&buf);
            Some(buf_hash)
        };
    }

    /// Generate F-S challenge point
    pub(crate) fn output(&self) -> Fr {
        let srs_hash = self.srs_hash.unwrap();
        let circuit_info_hash = self.circuit_info_hash.unwrap();
        let witness_commitment_hash = self.witness_commitment_hash.unwrap();
        let public_input_hash = self.public_input_hash.unwrap();

        let mut compile_time_bytes: Vec<u8> = Vec::new();
        compile_time_bytes.extend_from_slice(srs_hash.as_bytes());
        compile_time_bytes.extend_from_slice(circuit_info_hash.as_bytes());
        let compiletime_hash = blake3::hash(&compile_time_bytes);

        let mut runtime_bytes: Vec<u8> = Vec::new();
        runtime_bytes.extend_from_slice(witness_commitment_hash.as_bytes());
        runtime_bytes.extend_from_slice(public_input_hash.as_bytes());
        let runtime_hash = blake3::hash(&runtime_bytes);

        let mut root_bytes: Vec<u8> = Vec::new();
        root_bytes.extend_from_slice(compiletime_hash.as_bytes());
        root_bytes.extend_from_slice(runtime_hash.as_bytes());

        let root_hash = blake3::hash(&root_bytes);
        // Blake3 hash is in little-endian form
        // so we truncate by masking bits at MSB positions

        let mut root_hash_bytes = *root_hash.as_bytes();
        // truncate msb
        root_hash_bytes[28..].copy_from_slice(&[0, 0, 0, 0]); // mask top 4 bytes, 256-32=224 bits

        // deserialize bytes in little-endian format to BigUint
        let bigu = BigUint::from_bytes_le(&root_hash_bytes);
        // 224 bits fits well in 232 bit scalar field cleanly, so doesn't wrap around

        Fr::from(bigu)
    }
}

/// Prover `Precomputes` received from third party that would have otherwise taken long to compute oneself.
// Computes fields like tree2n_fast, barycentric_weights that are easy enough to compute
/// Contains data precomputed by the prover to accelerate proof generation.
///
/// These objects depend only on the cryptographic domain and can be reused
/// for any proof generated within that same domain, improving
/// performance.
/// Among these computing `vanishing_poly` takes the most time because
/// it takes O(N log^2 N) for N=2^23. Generating `tree2n` is more lenient because
/// we need an FFTree with only fields necessary for `FFTree::extend()`
///
/// # Fields
///
/// * `tree2n`: An `FFTree` over the domain $D \cup D'$.
/// * `vanishing_poly`: The vanishing polynomial over the domain $D$.
/// * `barycentric_weights`: Barycentric weights over $D$.
/// * `z_vals2inv`: The inverse of the vanishing polynomial evaluated over the domain $D'$.
///
/// `vanishing_poly` and `barycentric_weights` are used to evaluate witness polynomials a(X), b(X), i(X)
/// at random point `challenge` in O(N) time using function `evaluate_at_alpha_from_barycentric_weights`
/// `z_vals2inv` is used to compute quotient polynomial.
/// `tree2n` is used to call extend() and get the domain.
pub fn prover_prepares_precomputes(cache_dir: impl AsRef<Path>) -> Result<()> {
    let cache_dir = cache_dir.as_ref();
    std::fs::create_dir_all(cache_dir)
        .with_context(|| format!("creating cache dir {}", cache_dir.display()))?;

    let must_read = |fname: &str| -> Result<Vec<Fr>> {
        let path = cache_dir.join(fname);
        read_fr_vec_from_file(&path)
            .with_context(|| format!("expected preâ€‘computed {:?}", path.display()))
    };

    let zpoly = must_read(Z_POLY)?;
    let num_constraints = zpoly.len() - 1;

    let n_log = num_constraints.ilog2() as usize;

    let load_tree = |name: &str, shift_to_odd_domain: bool| -> Result<FFTree<Fr>> {
        let path = cache_dir.join(name);
        if path.exists() {
            println!("Reading {:?} â€¦", path.display());
            read_fftree_from_file(&path)
        } else {
            println!("Computing {:?} â€¦", path.display());
            let minimal_tree = true;
            // We require the tree to only include fields necessary for `FFTree::extend()`, so we load a `minimal` tree
            // This puts lesser memory requirement
            let tree = build_sect_ecfft_tree(
                num_constraints * 2,
                shift_to_odd_domain,
                n_log + 1,
                minimal_tree,
            )
            .unwrap();
            write_fftree_to_file(&tree, &path)?;
            Ok(tree)
        }
    };

    println!("Building ECFFT trees â€¦");
    let shift_to_odd_domain = false;
    // For 2n sized domain, we generate regular FFTree with regular structure to FFTree::leaves
    // so shift_to_odd_domain is false
    let _ = load_tree(TREE_2N, shift_to_odd_domain)?; // 2Â·n domain

    let _ = must_read(BAR_WTS)?;
    let _ = must_read(Z_VALS2_INV)?;

    // TODO: @manishbista28
    // add functions to verify that the precomputed values obtained from a third party were valid;
    // The received values that were precomputed and made available by a third party include `vanishing_poly`,
    // `barycentric_weights` and `z_vals2inv`
    // vanishing_poly: Verify by ensuring it is of degree m+1 and ensuring that it evaluates to zero at all points in domain D
    // barycentric_weights and z_vals2inv can be computed by the prover himself given `vanishing_poly` because they don't take much time

    Ok(())
}

/// R1CS constraint matrices x witness vectors => constraint evaluations
struct Evals {
    a: Vec<Fr>,
    b: Vec<Fr>,
    c: Vec<Fr>,
    i: Vec<Fr>,
}

impl Evals {
    /// helper clear memory used by Evals instance
    fn clear(&mut self) {
        self.a.clear();
        self.b.clear();
        self.c.clear();
        self.i.clear();
    }
}

impl Proof {
    /// Given R1CS Matrices and Witness (public and private inputs), obtain gate evaluations.
    // Arrange inputs in right order, vector product to obtain evaluation and assert that the r1cs relation holds
    fn get_matrix_evaluations_from_witness(
        inst: &R1CSInstance,
        public_inputs: &[Fr],
        private_inputs: &[Fr],
        dom_elems: &[Fr],
    ) -> Evals {
        // Build assignment [1, public_inputs..., private_inputs...]
        let mut assignment =
            Vec::<Fr>::with_capacity(public_inputs.len() + private_inputs.len() + 1);
        assignment.push(Fr::one());
        assignment.extend_from_slice(public_inputs);
        assignment.extend_from_slice(private_inputs);

        assert_eq!(inst.num_public_inputs, public_inputs.len());
        assert!(inst.num_constraints.is_power_of_two());

        let m = inst.num_constraints;
        let mut a_vals = vec![Fr::zero(); m];
        let mut b_vals = vec![Fr::zero(); m];
        let mut c_vals = vec![Fr::zero(); m];

        let i_vals = {
            // evaluate monomial basis polynomial over 2 public inputs
            let mut i_vals = vec![Fr::ZERO; m];
            for i in 0..dom_elems.len() {
                i_vals[i] = evaluate_monomial_basis_poly(public_inputs, dom_elems[i]);
            }
            i_vals
        };

        println!("evaluate R1CS matrix at input to obtain gate evaluations");
        // constraints for i(X) polynomial

        // iterate through constraints
        for i in 0..inst.rows.len() {
            let row = &inst.rows[i];
            a_vals[i] = R1CSInstance::eval_row(&row.l, &inst.coeffs, &assignment);
            b_vals[i] = R1CSInstance::eval_row(&row.r, &inst.coeffs, &assignment);
            c_vals[i] = R1CSInstance::eval_row(&row.o, &inst.coeffs, &assignment);

            // ensure the relation a.b = c + i is satisfied; if satisfied, should be provable
            assert_eq!(
                a_vals[i] * b_vals[i],
                c_vals[i] + i_vals[i],
                "constraint {} of total {:?}",
                i,
                row
            );
        }
        Evals {
            a: a_vals,
            b: b_vals,
            c: c_vals,
            i: i_vals,
        }
    }

    /// Given evaluations in domain D, directly obtain the corresponding evaluations in domain D'
    // extend() operation is analogous to first representing the input `evals` by a polynomial
    // then evaluate the polynomial in domain D'
    // extend() just provides a direct and cheap O(N logN) way to obtain the evaluations
    // we need these to calculate quotient polynomial over D'
    fn extend_evals(tree2n: &FFTree<Fr>, evals: &Evals) -> Evals {
        println!("extend_evals");
        let a_vals2 = tree2n.extend(&evals.a, ecfft::Moiety::S1);
        let b_vals2 = tree2n.extend(&evals.b, ecfft::Moiety::S1);
        let c_vals2 = tree2n.extend(&evals.c, ecfft::Moiety::S1);
        let i_vals2 = tree2n.extend(&evals.i, ecfft::Moiety::S1);
        Evals {
            a: a_vals2,
            b: b_vals2,
            c: c_vals2,
            i: i_vals2,
        }
    }

    /// The main prove function
    // r1cs_instance is none if it's big
    pub fn prove(cache_dir: &str, public_inputs: Vec<Fr>, private_inputs: &[Fr]) -> Proof {
        // Initialize empty transcript
        let mut transcript = Transcript::default();

        println!("Compute commitment to witness polynomials");
        // `msm_gm` is the commitment to witness polynomial
        // we need `evals` to later compute quotient polynomial
        // `num_constraints` to initialize vector capacity
        let (msm_gm, mut evals, num_constraints) = {
            let tree2n: FFTree<Fr> =
                read_minimal_fftree_from_file(Path::new(&format!("{cache_dir}/{TREE_2N}")))
                    .unwrap();

            let doms = &get_both_domains(&tree2n)[0];

            let inst = R1CSInstance::initialize_with_vandermode_matrix_for_public_input_poly(
                &format!("{cache_dir}/{R1CS_CONSTRAINTS_FILE}"),
                doms,
                public_inputs.len(),
            );

            // prepare witness
            // r1cs matrix expects witness in this specific format
            let mut assignment = Vec::with_capacity(public_inputs.len() + private_inputs.len() + 1);
            assignment.push(Fr::one());
            assignment.extend_from_slice(&public_inputs);
            assignment.extend_from_slice(private_inputs);

            let evals = Self::get_matrix_evaluations_from_witness(
                &inst,
                &public_inputs,
                private_inputs,
                doms,
            );

            // msm_gm is part of witness commitment
            let g_m = read_point_vec_from_file(format!("{cache_dir}/{SRS_G_M}")).unwrap();
            let msm_gm = multi_scalar_mul(&assignment, &g_m);

            println!("Include circuit and public input in trascript");
            transcript.circuit_info_hash(&inst);
            transcript.public_input_hash(&public_inputs);
            (msm_gm, evals, inst.num_constraints)
        };

        println!("extend evaluations over domain D to D' ");
        // `evals2` is the evaluation of a(X), b(X), c(X), i(X) over domain D'
        // we need `dom_elems` and `dom2_elems` to compute kzg commitment later
        let (mut evals2, mut dom_elems, mut dom2_elems) = {
            let tree2n: FFTree<Fr> =
                read_minimal_fftree_from_file(Path::new(&format!("{cache_dir}/{TREE_2N}")))
                    .unwrap();

            let d_and_d_dash_domains = get_both_domains(&tree2n);

            // obtain evaluations of polynomial, that passes through evals over D, in D'
            let evals2 = Self::extend_evals(&tree2n, &evals);
            (
                evals2,
                d_and_d_dash_domains[0].clone(),
                d_and_d_dash_domains[1].clone(),
            )
        };

        println!("r_vals2");
        // r_vals2 represents evaluation of the polynomial r(X) = a(X) b(X) - i(X) over domain D'
        let mut r_vals2 = (0..num_constraints)
            .into_par_iter()
            .map(|i| evals2.a[i] * evals2.b[i] - evals2.i[i])
            .collect::<Vec<Fr>>();

        println!("Compute commitment to quotient polynomial");
        // Compute commitment to quotient polynomial
        let msm_q = {
            let q_vals2 = {
                let z_vals2inv =
                    read_fr_vec_from_file(format!("{cache_dir}/{Z_VALS2_INV}")).unwrap();
                // q_vals2 represents evaluation of the polynomial q(X) = (a(X) b(X) - i(X) -c(X)) / z(X) over domain D'

                (0..num_constraints)
                    .into_par_iter()
                    .map(|i| (r_vals2[i] - evals2.c[i]) * z_vals2inv[i])
                    .collect::<Vec<Fr>>()
            };

            let g_q = read_point_vec_from_file(format!("{cache_dir}/{SRS_G_Q}")).unwrap();
            multi_scalar_mul(&q_vals2, &g_q)
        };

        let commit_p = CurvePoint::add(msm_q, msm_gm);

        transcript.witness_commitment_hash(&[commit_p]);

        {
            let srs = SRS::empty();
            /*
               // commented out for now because it takes awfully long to hash this much data

               let g_m = read_point_vec_from_file(format!("{cache_dir}/g_m")).unwrap();
               let g_q = read_point_vec_from_file(format!("{cache_dir}/g_q")).unwrap();
               let g_qi = read_point_vec_from_file(format!("{cache_dir}/g_qi")).unwrap();
               let g_k: Vec<Vec<CurvePoint>> = (0..3)
                   .into_par_iter()
                   .map(|i| read_point_vec_from_file(format!("{cache_dir}/g_k_{i}")).unwrap())
                   .collect();
               let g_kimin = read_point_vec_from_file(format!("{cache_dir}/g_k_3")).unwrap();
               // todo: also add g_k4
               let srs = SRS {
                   g_m,
                   g_q,
                   g_kimin,
                   g_qi,
                   g_k: g_k.try_into().unwrap(),
               };
            */
            transcript.srs_hash(&srs);
        }

        // Fiat-Shamir challenge
        let alpha = {
            let alpha = transcript.output();

            assert!(
                // How probably is this ? total domain is of size 2 x 2^24, Fr scalar field is of size 2^224, so 1/2^(200)
                !dom_elems.contains(&alpha),
                "domain shouldn't contain alpha, else makes KZG division divide by zero"
            );
            assert!(
                !dom2_elems.contains(&alpha),
                "domain shouldn't contain alpha, else makes KZG division divide by zero"
            );
            alpha
        };

        println!("evaluate witness polynomials at challenge");
        let (a0, b0, r0) = {
            let vanishing_poly_coeffs =
                read_fr_vec_from_file(format!("{cache_dir}/{Z_POLY}")).unwrap();
            let barycentric_weights =
                read_fr_vec_from_file(format!("{cache_dir}/{BAR_WTS}")).unwrap();
            let vanishing_poly = DensePolynomial {
                coeffs: vanishing_poly_coeffs,
            };

            // Evaluate a,b,c,q at alpha
            let a0 = evaluate_poly_at_alpha_using_barycentric_weights(
                &dom_elems,
                &barycentric_weights,
                &vanishing_poly,
                &evals.a,
                alpha,
            );
            let b0 = evaluate_poly_at_alpha_using_barycentric_weights(
                &dom_elems,
                &barycentric_weights,
                &vanishing_poly,
                &evals.b,
                alpha,
            );
            let i0 = evaluate_poly_at_alpha_using_barycentric_weights(
                &dom_elems,
                &barycentric_weights,
                &vanishing_poly,
                &evals.i,
                alpha,
            );
            let r0 = a0 * b0 - i0;
            (a0, b0, r0)
        };

        println!("computing K scalars");

        println!("denom_invs");
        let mut denom_invs = {
            let mut denom_diffs: Vec<Fr> = (0..num_constraints)
                .into_par_iter()
                .map(|i| dom_elems[i] - alpha)
                .collect();
            ark_ff::batch_inversion(&mut denom_diffs);
            denom_diffs
        };

        println!("denom_invs2");
        let mut denom_invs2 = {
            let mut denom_diffs: Vec<Fr> = (0..num_constraints)
                .into_par_iter()
                .map(|i| dom2_elems[i] - alpha)
                .collect();
            ark_ff::batch_inversion(&mut denom_diffs);
            denom_diffs
        };

        println!("k_scalar_a");
        let mut k_scalar_a: Vec<Fr> = (0..num_constraints)
            .into_par_iter()
            .map(|i| {
                let denom_inv = denom_invs[i];
                (evals.a[i] - a0) * denom_inv
            })
            .collect();

        println!("k_scalar_b");
        let mut k_scalar_b: Vec<Fr> = (0..num_constraints)
            .into_par_iter()
            .map(|i| {
                let denom_inv = denom_invs[i];

                (evals.b[i] - b0) * denom_inv
            })
            .collect();

        println!("r_vals");
        let mut r_vals = (0..num_constraints)
            .into_par_iter()
            .map(|i| evals.a[i] * evals.b[i] - evals.i[i])
            .collect::<Vec<Fr>>();

        println!("k_scalar_r");
        let mut k_scalar_r: Vec<Fr> = (0..num_constraints)
            .into_par_iter()
            .map(|i| {
                let denom_inv = denom_invs[i];
                let kr_val = (r_vals[i] - r0) * denom_inv;
                let denom_inv = denom_invs2[i];
                let kr_val2 = (r_vals2[i] - r0) * denom_inv;
                [kr_val, kr_val2]
            })
            .flatten()
            .collect();

        // free up memory
        evals.clear();
        evals2.clear();
        dom_elems.clear();
        dom2_elems.clear();
        r_vals.clear();
        r_vals2.clear();
        denom_invs.clear();
        denom_invs2.clear();

        let mut srs_g_k: Vec<CurvePoint> = Vec::with_capacity(num_constraints * 3);
        const G_KS: [&str; 3] = [SRS_G_K_0, SRS_G_K_1, SRS_G_K_2];
        for item in &G_KS {
            let path = format!("{cache_dir}/{}", item);
            let mut gk = read_point_vec_from_file(path).unwrap();
            srs_g_k.append(&mut gk);
        }

        let mut srs_s_k = Vec::with_capacity(k_scalar_a.len() * 3);
        srs_s_k.append(&mut k_scalar_a);
        srs_s_k.append(&mut k_scalar_b);
        srs_s_k.append(&mut k_scalar_r);

        println!("msm g_k");
        let kzg_k = multi_scalar_mul(&srs_s_k, &srs_g_k);

        Self {
            commit_p: commit_p.to_bytes(),
            kzg_k: kzg_k.to_bytes(),
            a0: FrBits::from_fr(a0),
            b0: FrBits::from_fr(b0),
        }
    }

    /// serialize Proof
    pub fn to_bits(&self) -> Vec<bool> {
        fn u8_to_bits_le(n: u8) -> [bool; 8] {
            let v: Vec<bool> = (0..8).map(|i| (n >> i) & 1 != 0).collect();
            v.try_into().unwrap()
        }

        let mut commit_p: Vec<bool> = self
            .commit_p
            .iter()
            .flat_map(|x| u8_to_bits_le(*x).to_vec())
            .collect();
        let mut kzg_k: Vec<bool> = self
            .kzg_k
            .iter()
            .flat_map(|x| u8_to_bits_le(*x).to_vec())
            .collect();
        let mut a0 = self.a0.0.to_vec();
        let mut b0 = self.b0.0.to_vec();

        let mut witness: Vec<bool> = Vec::new();

        witness.append(&mut commit_p);
        witness.append(&mut kzg_k);
        witness.append(&mut a0);
        witness.append(&mut b0);

        witness
    }

    /// deserialize Proof
    pub fn from_bits(bits: Vec<bool>) -> Proof {
        fn bits_le_to_u8(bits: &[bool]) -> u8 {
            let mut n: u8 = 0;
            for (i, &bit) in bits.iter().enumerate() {
                if bit {
                    n |= 1 << i;
                }
            }
            n
        }

        let mut offset = 0;

        // commit_p: 30 bytes = 240 bits
        let commit_p: [u8; 30] = {
            let mut arr = [0u8; 30];
            for arr_i in &mut arr {
                *arr_i = bits_le_to_u8(&bits[offset..offset + 8]);
                offset += 8;
            }
            arr
        };

        // kzg_k: 30 bytes = 240 bits
        let kzg_k: [u8; 30] = {
            let mut arr = [0u8; 30];
            for arr_i in &mut arr {
                *arr_i = bits_le_to_u8(&bits[offset..offset + 8]);
                offset += 8;
            }
            arr
        };

        // a0: read the same number of bits as frref_to_bits(&a0) would output
        let a0_bit_len = 232; // You must define this to return bit length of a0 field
        let a0_bits: [bool; 232] = bits[offset..offset + a0_bit_len].try_into().unwrap();
        let a0 = FrBits(a0_bits);
        offset += a0_bit_len;

        // b0: same size as a0
        let b0_bits = bits[offset..offset + a0_bit_len].try_into().unwrap();
        let b0 = FrBits(b0_bits);

        Proof {
            commit_p,
            kzg_k,
            a0,
            b0,
        }
    }
}
